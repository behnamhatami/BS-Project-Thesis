\فصل{موتورهای جستجو}

با توجه به آمار جهانی اینترنت، در تاریخ 31‌ام مارچ 2008، $1/407$ میلیارد انسان، از اینترنت استفاده می‌نمایند. میزان نفوذ اینترنت به طور روز افزون در حال افزایش است. شبکه جهانی گسترده وب\زیرنوشت {World Wide Web} (که معمولاً به اختصار وب نامیده می‌شود)، یک سیستم از اسناد ابرمتن\زیرنوشت {Hyper text documents} به هم متصل است که به وسیله‌ی اینترنت قابل دسترسی هستند. با استفاده از یک مرورگر، کاربر امکان مشاهده‌ی صفحات وب که دارای محتوای داده‌ای، عکس، فیلم و سایر امکانات چند رسانه‌ای است را دارد و می‌تواند توسط لینک‌ها، بین آن‌ها جابه‌جا گردد.
\\
همان گونه که تعداد صفحات وب، به طور روزافزون در حال افزایش است، نیاز به موتور جستجو بیشتر احساس می‌گردد. در این فصل، ما توضیح مختصری در مورد المان‌های پایه‌ی هر سیستم جستجویی به همراه نحوه‌ی عملکرد آن المان را مورد بررسی قرار می‌دهیم. سپس، نقش خزنده‌های وب\زیرنوشت {Web crawlers}، که یکی از اصلی‌ترین بخش‌های اصلی هر سیستم جستجوی اینترنتی می‌باشد را مورد بررسی قرار خواهیم داد.

\قسمت{موتور جستجوی وب}
محتوای بسیاری از شبکه جهانی گسترده‌ی وب، قابل استفاده برای میلیون‌ها نفر است. بسیاری از افراد، دسترسی به صفحات وب را از نقاط آغازی مانند، Yahoo\زیرنوشت {www.yahoo.com} و MSN\زیرنوشت {www.msn.com} و... آغاز می‌نمایند. اما بسیار از افراد نیازمند اطلاعات، برای شروع فعالیت اینترنتی خود از موتورهای جستجو آغاز می‌نمایند. در این حالت، کاربر یک پرسمان\زیرنوشت {Query} ارسال می‌نماید، که معمولاً به صورت لیستی از کلیدواژه‌ها\زیرنوشت {Keywords} است و در پاسخ، لیستی از صفحات وب که احتمالاً مرتبط با درخواست کاربر بوده (معمولاً صفحاتی که دارای آن کلیدواژه‌ها بوده است) را دریافت می‌کند. در زمینه‌ی وب، موتورهای جستجو، در واقع به جستجوگرهایی گفته می‌شود، که در یک پایگاه داده‌ای\زیرنوشت {Database} از فایل‌های وب، جستجوی خود را انجام می‌دهد.

\قسمت{انواع موتورهای جستجو}
به طور کلی، سه نوع موتور جستجو وجود دارد:

\شروع{فقرات}

\فقره {موتورهای جستجویی که به وسیله‌ی ربات‌ها اجرا می‌شوند (معمولاً به خزنده‌ها، مورچه‌ها\زیرنوشت {Ants} یا عنکبوت‌ها\زیرنوشت {Spiders} معروفند).}

\فقره {موتورهای جستجویی که بر اساس ارسال‌های کاربران اجرا می‌شوند.}

\فقره {موتورهای جستجویی که بر اساس تلفیق دو نوع بالا به دست می‌آید.}

\پایان{فقرات}

دو نوع اصلی موتورهای جستجو در زیر به اختصار توضیح داده شده است:
\زیرقسمت {موتورهای جستجو مبتنی بر خزنده‌ها}

چنین موتورهای جستجویی، از تعدادی عامل‌های\زیرنوشت {Agents} نرم افزاری خودکار (که خزنده نامیده می‌شود) تشکیل شده است. این خزنده‌ها، صفحات وب را دریافت، اطلاعات و ابر تگ‌های\زیرنوشت {Metatags} آن را استخراج می‌کنند. همچنین برای دسترسی به تمام صفحات یک وب سایت و شاخص بندی\زیرنوشت {Indexing} آن‌ها، لینک‌های داخل صفحات را دنبال می‌کند. خزنده، تمام اطلاعات استخراج شده را، در یک مخزن مرکزی\زیرنوشت {Central Repository} ذخیره می‌نماید. سپس داده‌ها در مخزن شاخص بندی می‌گردد. خزنده همچنین به طور متناوب به صفحات بازیابی شده مراجعه می‌نماید و در صورت تغییر اطلاعات خود را به روز رسانی می‌نماید. تناوب چنین کاری توسط مدیر سیستم، تنظیم می‌گردد.

\زیرقسمت {موتورهای جستجو مبتنی بر انسان}

چنین موتورهای جستجویی، مبتنی است بر داده‌هایی که به مرور زمان به وسیله‌ی انسان، به سیستم ارسال می‌شود، شاخص بندی می‌گردد و دسته بندی\زیرنوشت {Classified} می‌گردد. در این نوع موتور جستجوها، تنها داده‌هایی که ارسال شده است، در شاخص‌ها ذخیره می‌شود. چنین موتورهای جستجویی به ندرت در مقیاس بزرگ مورد استفاده می‌گردد، اما در سازمان‌هایی که با داده‌های با مقیاس کوچک روبرو هستند، بسیار پراستفاده است.

\قسمت {ساختار و نحوه ی کار موتورهای جستجو}

ساختار پایه‌ی هر موتور جستجویی مبتنی بر خزنده، در شکل ~\ref{fig:query_crawling} نشان داده شده است. از این رو، فازهای اصلی هر موتور جستجویی عبارتند از:

\شکل‌پی‌ان‌جی{10}{ساختار و نحوه ی کار یک موتور جستجو}{query_crawling}

\زیرقسمت{جمع آوری اطلاعات یا خزش}

هر موتور جستجویی که بر پایه‌ی یک خزنده کار می‌کند، منابع اطلاعاتی خود را برای ارائه‌ی خدمات تأمین می‌کند. خزنده‌ها، نرم افزارهای کوچکی هستند که از طریق موتورهای جستجو به سایت‌ها سر می‌زنند، دقیقاً به‌‌ همان روشی که انسان‌ها لینک‌های بین صفحات را دنبال می‌کنند. معمولاً در ابتدا، یک لیست ابتدایی از آدرس وب سایت‌ها به هر خزنده داده می‌شود. خزنده باید صفحه‌ی مربوط به هرکدام را دریافت نماید. پس از آن، لینک‌های داخل این صفحات بازیابی شده را استخراج نماید و اطلاعات استخراج شده را به واحد کنترل خزنده تحویل دهد. این واحد تصمیم می‌گیرد که چه لینک‌هایی در ادامه بازیابی گردد و لیست آن‌ها را برای خزنده ارسال می‌نماید.
مراحل بیان شده را می‌توانید در شکل ~\ref {fig:WebCrawler-architecture} ببینید.

\شکل‌پی‌ان‌جی{10}{نحوه ی کار خزنده}{WebCrawler-architecture}

\زیرقسمت{نگه داری پایگاه داده یا مخزن}
همان طور که در شکل ~\ref{fig:query_crawling} می‌بینید، تمام داده‌های یک موتور جستجو، در یک پایگاه داده ذخیره می‌شود و تمام جستجو‌ها و عملیات داده‌ای، به کمک این پایگاه داده انجام می‌پذیرد. این پایگاه داده نیاز دارد در طول زمان با توجه به تغییرهای بیرونی بروز رسانی گردد. در مرحله‌ی بازیابی و پس از اتمام مرحله دریافت اطلاعات به وسیله‌ی خزنده، موتور جستجو باید تمام اطلاعات جدید و مفید صفحات بازیابی شده را استخراج و در پایگاه داده ذخیره نماید. در بعضی از موتورهای جستجو، یک مخزن از صفحات ذخیره شده به صورت موقت بین این دو مرحله قرار می‌گیرد. حتی بعضی مواقع، موتورهای جستجو، یک حافظه‌ی سریع نهان\زیرنوشت {Cache} از صفحاتی که بازیابی شده‌اند، نگه می‌دارد تا بتواند مرحله‌ی شاخص بندی را سریع‌تر انجام دهد و همچنین امکان جستجوی ابتدایی بر روی داده‌های دریافت شده را فراهم آورد.

\زیرقسمت{شاخص بندی}
زمانی که صفحه‌ی بازیابی شده، در مخزن ذخیره می‌شود، کار بعدی موتور جستجو، ایجاد یک شاخص برای داده‌های ذخیره شده می‌باشد. واحد شاخص بندی، تمام کلمات را از هر صفحه استخراج می‌نماید و آدرس صفحه‌ی مدنظر را به ازای هر کلمه‌ی استخراج شده، ذخیره می‌نماید. نتیجه کار، معمولاً یک لغت نامه‌ی بزرگ می‌باشد که می‌تواند آدرس تمام صفحه‌هایی را که در آن‌ها کلمه‌ی خاصی آمده‌اند را به ما بدهد. به وضوح صفحات به صفحاتی محدود می‌شود که در فاز قبلی بازیابی شده‌اند. همان طور که قبلاً ذکر شده بود، شاخص بندی متن، مشکلات و چالش‌های خاص خودش را دارد. از جمله‌ی آن می‌توان به سایز بزرگ آن و سرعت زیاد تغییرات در آن اشاره نمود. همچنین علاوه بر چالش‌های فوق‌الذکر، جستجو برای شاخص‌های نادر و کمتر رایج نیز خود چالش زا است. به طور مثال، واحد شاخص بندی، می‌تواند یک شاخص ساختاری از اتصالات بین صفحات تولید نماید.

\زیرقسمت{پرسمان}
این واحد با پرسمان‌های کاربر سروکار دارد. واحد پرسمان، مسئول دریافت و پاسخ گویی به درخواست‌های جستجو از طرف کاربران می‌باشد. این واحد به صورت اساسی وابسته به شاخص‌های موجود و بعضی مواقع به مخزن صفحات ذخیره می‌باشد. به علت حجم زیاد وب، و وارد شدن عبارات جستجوی کوتاه به وسیله کاربران در حد یک یا دو کلیدواژه، مجموعه جواب موجود، بسیار زیاد می‌باشد.

\زیرقسمت{رتبه بندی}
به علت اینکه مجموعه سندهای مرتبط با پرسمان وارد شده‌ی کاربر، بسیار زیاد است، یکی از مهم‌ترین وظایف موتورهای جستجو نمایش مرتبط‌ترین نتایج به کاربر است. برای اجرای کارآمد چنین امری، نتایج رتبه دهی می‌گردند. واحد رتبه دهی، به همین منظور وظیفه‌ی مرتب کردن نتایج را به گونه ای دارد که نتایج بالاتر احتمال بیشتری داشته باشند که همان اسنادی که کاربر به دنبال آن است باشند.
\\
پس از پیدا کردن نتایج، به وسیله‌ی واحد رتبه دهی به هر یک از نتایج رتبه اختصاص داده شد، نتایج نهایی جستجو به کاربر نشان داده می‌شود. این روشی است که تقریباً تمام موتورهای جستجو مطابق آن کار می‌کنند.

\قسمت{نمونه‌ی موتورهای جستجو}
تعدادی موتور جستجو در حال حاضر قابل استفاده است. در زیر لیستی از مهم‌ترین و مشهور‌ترین موتورهای جستجو آورده شده است:

\شروع{فقرات}

\فقره{Google}\زیرنوشت{www.google.com}
\فقره{Yahoo}
\فقره{MSN}
\فقره{E-Bay}\زیرنوشت{www.ebay.com}
\فقره{AOl}\زیرنوشت{www.aol.com}

\پایان{فقرات} 
و تعداد بسیار زیادی موتور جستجوی دیگر در دسترس هست که کاربران را برای رسیدن به اطلاعات مدنظر یاری می‌نماید.

\قسمت{خلاصه‌ی فصل}
موتورهای جستجو، به عنوان کلید اصلی ورود به جهان گسترده وب است. تکامل و اجزای موتورهای جستجو قسمتی مهمی از مطالعه‌ی جهان گسترده‌ی وب هستند. قسمت‌های ضروری موتور جستجو، عبارتند از خزنده، استخراج کننده، برنامه ریز و پایگاه داده. بعضی از مهم‌ترین موتورهای جستجوی پرکاربرد عبارتند از Google و MSN و ... .
\\