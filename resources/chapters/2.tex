\فصل{معرفی مسئله}

\قسمت{تعریف دقیق مسأله}
هدف از انجام این پژوهش، پیاده سازی موتورهای جستجوی هوشمند کسب و کار فارسی است.

روزانه حجم بالایی از آگهی‌های استخدام، در فضای برخط و در قالب صفحات وب و یا صفحات شخصی افراد، منتشر می‌شوند. از طرفی تعداد این صفحات بسیار زیاد است و به روز رسانی صفحات معمولاً از سرعت بالایی (تقریباً هر روز) برخوردار است. از طرفی دیگر، اغلب این صفحات، آگهی‌هایی در همه‌ی زمینه‌های موضوعی و شغلی و همچنین شرایط مکانی نظیر شهر و استان محل کار را پوشش می‌دهند.
\\
در حال حاضر، در چند مورد از سایت‌های فارسی که در زمینه‌ی استخدام فعالیت می‌کنند، امکان دسته بندی مطالب بر حسب نوع آگهی وجود دارد، اما این دسته‌بندی توسط انسان و بدون استفاده از روش‌های یادگیری انجام می‌شود و در بسیاری از موارد متأسفانه دسته‌بندی موجود، چندان کامل نیست. همچنین امکان جستجو اغلب به صورت جستجوی متنی در این سایت‌ها وجود دارد و امکان جستجو با توجه به مواردی همچون جنسیت فرد، نوع شغل و موقعیت مکانی آن وجود ندارد. همچنین تعامل آن‌ها با افراد با استفاده از روش‌هایی مانند عضویت و یا ارسال نظر و در مواردی اندک، ارسال رزومه است. اما در روش‌های تعاملی و گزینش خبرهای مرتبط با افراد نیز متأسفانه از روش‌های هوشمند استفاده نمی‌شود و این کار با استفاده از نیروی انسانی صورت می‌گیرد.
\\
با توجه به ویژگی‌های مطرح شده برای این صفحات وب، مشاهده و جستجوی روزانه در میان حجم انبوه اخبار و آگهی‌ها، بدون استفاده از روش‌های هوش مصنوعی و تنها با استفاده از نیروی انسانی هم برای یافتن افراد متناسب با شغل و گزینش با توجه به توانایی آن‌ها و هم برای فرد متقاضی، کاری بسیار دشوار است. بنابراین می‌توان از الگوریتم‌های یادگیری در قسمت دریافت اخبار و پیمایش صفحات وب و همچنین تعامل با متقاضی و همچنین دسته‌بندی آگهی‌ها و اخبار استفاده کرد.
\\
در این پژوهش، با استفاده از تکنولوژی‌های موجود برای بازیابی و اختصاصی سازی آن‌ها، از سایت‌هایی که در زمینه‌ی استخدام فعالیت دارند، آگهی‌های استخدام استخراج می‌شود و با پردازش هرکدام، اطلاعات تخصصی مورد نیاز جداسازی شده و سپس شاخص بندی و برای اجرای انواع پرسمان‌ها توسط تکنولوژی‌های موجود آماده می‌گردد.
\\
در این پژوهش، برای بازیابی اطلاعات از نرم افزار متن باز\زیرنوشت {Open source} Nutch\زیرنوشت {nutch.apache.org}، استفاده می‌شود. این نرم افزار، دارای امکانات و ویژگی‌های خاص خود می‌باشد و امکان پیکربندی بالایی دارد. سپس اطلاعات بازیابی شده را به وسیله‌ی Lucene\زیرنوشت {lucene.apache.org}، شاخص بندی می‌کنیم. این نرم افزار یکی از بهترین نرم افزارهای متن باز در این زمینه است. سپس با استفاده از Solr\زیرنوشت {lucene.apache.org/solr}، امکان پرسمان بر روی اطلاعات استخراج شده فراهم خواهیم کرد. سپس اطلاعات به دست آمده به پژوهش مکمل برای پردازش‌های بعدی داده می‌شود.
\\
در پژوهش مکمل، از الگوریتم‌های یادگیری برای هوشمند کردن دسته‌بندی آگهی‌ها و اخبار استفاده می‌شود. این سامانه‌ی هوشمند، از اطلاعات پیمایش شده‌ی صفحات وب استفاده می‌کند، بنابراین ورودی مسئله تعدادی از آگهی‌های فارسی است. هدف دسته‌بندی آگهی‌ها بر اساس موضوع آن‌هاست، به گونه‌ای که هر آگهی بتواند در یک یا چند دسته با موضوع مرتبط با خود قرار بگیرد. این مسئله همانند مسئله‌ی مدل‌سازی عناوین است. به این صورت که تعدادی سند (در قالب آگهی) در اختیار داشته و هدف نهایی قرار دادن این اسناد در یک یا چند دسته و بدست آوردن این دسته‌هاست. بنابراین از دو الگوریتم LDA و PLSA که در ادامه شرح داده خواهد شد، برای حل این مسئله استفاده می‌شود. البته باید توجه کرد که در مدل‌سازی عناوین، تاپیک‌ها به صورت هوشمند نام‌گذاری نمی‌شوند. 
\\
بنابراین نام‌گذاری مناسب دسته‌ها جزئی از راه حل مسئله محسوب می‌شود. در نهایت خروجی این مسئله، تعدادی موضوع با عناوینی همچون «استخدام بانک‌ها»، «استخدام نیروی انتظامی» و یا به تفکیک مکانی مانند «استخدام استان تهران» و «استخدام استان اصفهان» و همچنین اسناد مرتبط با هر یک از موضوعات می‌باشد.

\قسمت{کارهای مشابه}

در زمینه‌ی کسب و کار هوشمند آنلاین، در زبان‌های دیگر کارهای مشابهی انجام شده است که از جمله آن‌ها می‌توان به صفحه‌ی وب Texkernel\زیرنوشت {www.texkernel.com} اشاره کرد. این سایت از 6 قسمت اصلی تشکیل شده است که به صورت مجتمع در کنار یکدیگر قرار گرفته‌اند و از هر یک از این سرویس‌ها می‌توان به صورت جداگانه استفاده کرد. در زیر به اختصار به هر یک از این سرویس‌ها و ویژگی‌های آن‌ها اشاره می‌کنیم:
\شروع{فقرات}

\فقره{قسمت استخراج که قسمت‌های مختلف رزومه را به صورت خودکار از روی کارنامک\زیرنوشت {Curriculum vitae (CV)} و یا صفحه‌ی کاربر در رسانه‌های اجتماعی و تکمیل پروفایل کاربر به صورت اتوماتیک استخراج می‌کند.}

\فقره{قسمت منابع که به صورت اتوماتیک کارنامک و اطلاعات فرد در شبکه‌های اجتماعی را جدا کرده و به صورت گرافیکی در کنار رزومه‌ی اصلی فرد قرار می‌دهد و به کاربر امکان ویرایش و اضافه یا حذف اطلاعات از کارنامک خود در پایگاه داده‌ی سایت را می‌دهد. پس از این مرحله اطلاعات فرد در پایگاه داده‌ی صفحه ذخیره می‌شود تا در مراحل بعدی مورد استفاده قرار گیرد.}

\فقره{قسمت جستجو امکان جستجو در میان رزومه‌های موجود در پایگاه داده برای یافتن افراد مرتبط با هر شغل و رتبه‌بندی آن‌ها را می‌دهد.}

\فقره{قسمت خوراک شغل\زیرنوشت {JobFeed} که به صورت خودکار به صورت روزانه در سایت‌های کسب و کار جستجو می‌کند و آگهی‌های جدید را پردازش کرده و قسمت‌های مورد نیاز را از آن استخراج می‌کند.}

\فقره{قسمت وصل کردن که متن آگهی کار را دریافت کرده و به صورت خودکار، افراد متناسب با آن شغل بر روی پایگاه داده‌ها جستجو و به صورت فهرست بدست می‌آیند.}

\فقره{قسمت برداشت که به صورت خودکار، شغل‌های متناسب با توانایی و شرایط کاربر که بر روی خوراک شغل قرار دارد را به او نشان می‌دهد.}

\پایان{فقرات}

هر یک از این بخش‌ها به صورت جداگانه قابل دسترسی و استفاده در صفحه مورد نظر هستند. اما متأسفانه هیچ یک از این بخش‌ها از زبان فارسی پشتیبانی نمی‌کند.
\\
کار انجام شده در این پژوهش مشابه بخش خوراک شغل است و اطلاعات مورد نیاز را از آگهی‌های فارسی استخراج می‌کند.
\\
از ویژگی‌های اصلی قسمت خوراک شغل سایت textkernel می‌توان به موارد زیر اشاره کرد:
\شروع{فقرات}

\فقره{مقایسه هر آگهی با آگهی‌های دریافت شده در 6 ماه اخیر و تشخیص شغل‌های یکتا و رفتار کارفرماها}

\فقره{به روز رسانی و بررسی وضعیت شغل‌ها از نظر باز یا بسته بودن و همچنین ظرفیت باقیمانده از شغل به صورت روزانه}

\فقره{داشتن پیوند به صفحه‌ی فرد در شبکه‌ی اجتماعی Linkedin}\زیرنوشت {www.linkedin.com}

\پایان{فقرات}

قابل ذکر است، که نوع کارنامک فرد، باید ساختاری مشابه ساختار Linkedin باشد، به همین علت، بررسی دقیق Linkedin برای این پروژه نیاز است.